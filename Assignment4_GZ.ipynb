{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c0c4371",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08824200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sympy.printing.tensorflow import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e45298",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79480bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "5        6  2011-01-01       1   0     1   5        0        6           0   \n",
       "6        7  2011-01-01       1   0     1   6        0        6           0   \n",
       "7        8  2011-01-01       1   0     1   7        0        6           0   \n",
       "8        9  2011-01-01       1   0     1   8        0        6           0   \n",
       "9       10  2011-01-01       1   0     1   9        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81     0.0000       3          13   16  \n",
       "1           1  0.22  0.2727  0.80     0.0000       8          32   40  \n",
       "2           1  0.22  0.2727  0.80     0.0000       5          27   32  \n",
       "3           1  0.24  0.2879  0.75     0.0000       3          10   13  \n",
       "4           1  0.24  0.2879  0.75     0.0000       0           1    1  \n",
       "5           2  0.24  0.2576  0.75     0.0896       0           1    1  \n",
       "6           1  0.22  0.2727  0.80     0.0000       2           0    2  \n",
       "7           1  0.20  0.2576  0.86     0.0000       1           2    3  \n",
       "8           1  0.24  0.2879  0.75     0.0000       1           7    8  \n",
       "9           1  0.32  0.3485  0.76     0.0000       8           6   14  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the URL from which to fetch the CSV data.\n",
    "url = 'https://raw.githubusercontent.com/zhenliangma/Applied-AI-in-Transportation/master/Exercise_7_Neural_networks/Exercise7BikeSharing.csv'\n",
    "\n",
    "# Use pandas to read the CSV data from the specified URL and store it in a DataFrame 'df'.\n",
    "df = pd.read_csv(url)\n",
    "# Display the first 10 rows of the DataFrame 'df'.\n",
    "#df = pd.read_csv('Exercise7BikeSharing.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73e95c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'cnt'\n",
    "features = [\n",
    "    'temp', 'atemp', 'hum', 'windspeed', 'weathersit',\n",
    "    'hr', 'weekday', 'workingday', 'holiday', 'season'\n",
    "]\n",
    "\n",
    "# --- Feature Engineering: Add interaction features ---\n",
    "# 1. Create new columns in the DataFrame for the interaction features.\n",
    "df['hr_workingday_interaction'] = df['hr'] * df['workingday']\n",
    "df['weather_hum_interaction'] = df['weathersit'] * df['hum']\n",
    "\n",
    "# 2. Add the names of the new features to your features list.\n",
    "# This is a crucial step to ensure they are included in the model training.\n",
    "features.append('hr_workingday_interaction')\n",
    "features.append('weather_hum_interaction')\n",
    "\n",
    "# Now, create X and y with the newly expanded feature set.\n",
    "X = df[features].copy()\n",
    "y = df[target].astype(float)\n",
    "\n",
    "\n",
    "# Train/test split (this part remains the same)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features (important for NN) (this part remains the same)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "92b140e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LR_MSE': 20707.869688812185, 'LR_MAE': 106.69134447648158, 'LR_R2': 0.34604134875169}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr) #,squared=False\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print({\"LR_MSE\": mse_lr, \"LR_MAE\": mae_lr, \"LR_R2\": r2_lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2034c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def construct_network_model(layer_sizes, dropout_rate, input_dim, learning_rate):\n",
    "    \"\"\"\n",
    "    Function to create and compile a Keras model using a more robust structure.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Use a standalone Input layer for clarity.\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    \n",
    "    # Use a single, unified loop to create all hidden layers.\n",
    "    for size in layer_sizes:\n",
    "        model.add(Dense(size, activation='relu'))\n",
    "        # Apply Dropout consistently after each hidden layer (if rate > 0).\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "            \n",
    "    # Add the output layer for regression.\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Compile the model.\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss='mae',\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d7170729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 90 candidates, totalling 180 fits\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 32], model__learning_rate=0.01; total time=  47.1s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 32], model__learning_rate=0.001; total time=  47.6s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 32], model__learning_rate=0.001; total time=  48.1s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 64, 32], model__learning_rate=0.1; total time=  49.9s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 64, 32], model__learning_rate=0.01; total time=  50.0s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 64, 32], model__learning_rate=0.001; total time=  50.2s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 64, 32], model__learning_rate=0.01; total time=  50.3s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 64, 32], model__learning_rate=0.1; total time=  51.0s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 64, 32], model__learning_rate=0.001; total time=  51.3s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 32], model__learning_rate=0.01; total time=  50.9s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 32], model__learning_rate=0.1; total time=  50.6s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 32], model__learning_rate=0.1; total time=  50.4s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 64], model__learning_rate=0.01; total time=  49.8s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 64], model__learning_rate=0.001; total time=  51.0s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 64], model__learning_rate=0.001; total time=  51.1s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 64], model__learning_rate=0.01; total time=  51.3s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 64], model__learning_rate=0.1; total time=  51.1s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 64], model__learning_rate=0.1; total time=  51.1s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 128, 64], model__learning_rate=0.001; total time= 1.0min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 128, 64], model__learning_rate=0.01; total time= 1.0min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 128, 64], model__learning_rate=0.001; total time= 1.0min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 128, 64], model__learning_rate=0.01; total time= 1.0min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 128, 64], model__learning_rate=0.1; total time= 1.0min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 128, 64], model__learning_rate=0.1; total time= 1.0min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[256, 128, 64], model__learning_rate=0.01; total time= 1.1min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[256, 128, 64], model__learning_rate=0.001; total time= 1.2min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[256, 128, 64], model__learning_rate=0.001; total time= 1.2min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 64, 32], model__learning_rate=0.001; total time= 1.4min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 64, 32], model__learning_rate=0.001; total time= 1.4min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 64, 32], model__learning_rate=0.01; total time= 1.4min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[256, 128, 64], model__learning_rate=0.01; total time= 1.5min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[256, 128, 64], model__learning_rate=0.1; total time= 1.5min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[256, 128, 64], model__learning_rate=0.1; total time= 1.5min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 64, 32], model__learning_rate=0.01; total time= 1.4min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 64, 32], model__learning_rate=0.1; total time= 1.4min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 64, 32], model__learning_rate=0.1; total time= 1.4min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 32], model__learning_rate=0.001; total time=  54.2s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 32], model__learning_rate=0.001; total time=  55.2s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 32], model__learning_rate=0.01; total time=  54.7s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 32], model__learning_rate=0.01; total time=  54.7s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 32], model__learning_rate=0.1; total time=  55.1s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 32], model__learning_rate=0.1; total time=  55.8s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 64], model__learning_rate=0.001; total time=  55.6s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 64], model__learning_rate=0.01; total time=  56.0s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 64], model__learning_rate=0.001; total time=  56.7s\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 64], model__learning_rate=0.01; total time= 1.0min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 64], model__learning_rate=0.1; total time= 1.1min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 64], model__learning_rate=0.1; total time= 1.1min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 128, 64], model__learning_rate=0.001; total time= 1.3min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 128, 64], model__learning_rate=0.01; total time= 1.3min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 128, 64], model__learning_rate=0.001; total time= 1.3min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 128, 64], model__learning_rate=0.01; total time= 1.3min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 128, 64], model__learning_rate=0.1; total time= 1.3min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 128, 64], model__learning_rate=0.1; total time= 1.4min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[256, 128, 64], model__learning_rate=0.001; total time= 1.5min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[256, 128, 64], model__learning_rate=0.001; total time= 1.5min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[256, 128, 64], model__learning_rate=0.01; total time= 1.5min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 64, 32], model__learning_rate=0.001; total time= 1.3min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 64, 32], model__learning_rate=0.001; total time= 1.2min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 64, 32], model__learning_rate=0.01; total time= 1.2min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[256, 128, 64], model__learning_rate=0.01; total time= 1.4min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[256, 128, 64], model__learning_rate=0.1; total time= 1.4min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[256, 128, 64], model__learning_rate=0.1; total time= 1.5min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 64, 32], model__learning_rate=0.01; total time= 1.2min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 64, 32], model__learning_rate=0.1; total time= 1.2min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 32], model__learning_rate=0.001; total time= 1.1min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 32], model__learning_rate=0.001; total time= 1.0min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 32], model__learning_rate=0.01; total time= 1.1min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 32], model__learning_rate=0.01; total time= 1.1min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 64, 32], model__learning_rate=0.1; total time= 1.3min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 32], model__learning_rate=0.1; total time= 1.1min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 32], model__learning_rate=0.1; total time= 1.1min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 64], model__learning_rate=0.001; total time= 1.1min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 64], model__learning_rate=0.001; total time= 1.1min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 64], model__learning_rate=0.01; total time= 1.2min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 64], model__learning_rate=0.01; total time= 1.1min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 64], model__learning_rate=0.1; total time= 1.1min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 64], model__learning_rate=0.1; total time= 1.2min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 128, 64], model__learning_rate=0.001; total time= 1.4min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 128, 64], model__learning_rate=0.01; total time= 1.4min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 128, 64], model__learning_rate=0.001; total time= 1.4min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 128, 64], model__learning_rate=0.01; total time= 1.5min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 128, 64], model__learning_rate=0.1; total time= 1.5min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 128, 64], model__learning_rate=0.1; total time= 1.5min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[256, 128, 64], model__learning_rate=0.001; total time= 1.6min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[256, 128, 64], model__learning_rate=0.01; total time= 1.6min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[256, 128, 64], model__learning_rate=0.001; total time= 1.6min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[256, 128, 64], model__learning_rate=0.01; total time= 1.6min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[256, 128, 64], model__learning_rate=0.1; total time= 1.6min\n",
      "[CV] END batch_size=32, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[256, 128, 64], model__learning_rate=0.1; total time= 1.6min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 64, 32], model__learning_rate=0.001; total time=  45.9s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 64, 32], model__learning_rate=0.01; total time=  46.0s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 64, 32], model__learning_rate=0.001; total time=  46.7s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 64, 32], model__learning_rate=0.01; total time=  45.7s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 64, 32], model__learning_rate=0.1; total time=  45.0s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 64, 32], model__learning_rate=0.1; total time=  45.6s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 32], model__learning_rate=0.001; total time=  42.1s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 32], model__learning_rate=0.001; total time=  40.6s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 32], model__learning_rate=0.01; total time=  41.0s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 32], model__learning_rate=0.01; total time=  40.8s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 32], model__learning_rate=0.1; total time=  41.0s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 32], model__learning_rate=0.1; total time=  41.5s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 64], model__learning_rate=0.001; total time=  41.2s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 64], model__learning_rate=0.001; total time=  41.5s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 64], model__learning_rate=0.01; total time=  40.9s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 64], model__learning_rate=0.01; total time=  42.5s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 64], model__learning_rate=0.1; total time=  43.9s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[64, 64], model__learning_rate=0.1; total time=  42.2s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 128, 64], model__learning_rate=0.001; total time=  51.9s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 128, 64], model__learning_rate=0.001; total time=  51.8s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 128, 64], model__learning_rate=0.01; total time=  51.9s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 128, 64], model__learning_rate=0.01; total time=  52.7s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 128, 64], model__learning_rate=0.1; total time=  53.2s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[128, 128, 64], model__learning_rate=0.1; total time=  53.8s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[256, 128, 64], model__learning_rate=0.001; total time= 1.0min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[256, 128, 64], model__learning_rate=0.001; total time= 1.0min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[256, 128, 64], model__learning_rate=0.01; total time= 1.0min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[256, 128, 64], model__learning_rate=0.01; total time= 1.1min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[256, 128, 64], model__learning_rate=0.1; total time= 1.0min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 64, 32], model__learning_rate=0.001; total time=  53.6s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.0, model__layer_sizes=[256, 128, 64], model__learning_rate=0.1; total time= 1.1min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 64, 32], model__learning_rate=0.001; total time=  53.3s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 64, 32], model__learning_rate=0.01; total time=  53.5s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 64, 32], model__learning_rate=0.01; total time=  50.9s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 64, 32], model__learning_rate=0.1; total time=  51.1s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 64, 32], model__learning_rate=0.1; total time=  51.1s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 32], model__learning_rate=0.001; total time=  46.7s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 32], model__learning_rate=0.01; total time=  45.9s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 32], model__learning_rate=0.001; total time=  46.7s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 32], model__learning_rate=0.01; total time=  45.9s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 32], model__learning_rate=0.1; total time=  46.1s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 32], model__learning_rate=0.1; total time=  47.2s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 64], model__learning_rate=0.001; total time=  47.1s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 64], model__learning_rate=0.001; total time=  46.6s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 64], model__learning_rate=0.01; total time=  46.9s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 64], model__learning_rate=0.01; total time=  47.2s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 64], model__learning_rate=0.1; total time=  46.7s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[64, 64], model__learning_rate=0.1; total time=  47.7s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 128, 64], model__learning_rate=0.001; total time=  57.1s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 128, 64], model__learning_rate=0.01; total time=  56.7s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 128, 64], model__learning_rate=0.001; total time=  57.8s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 128, 64], model__learning_rate=0.01; total time=  59.4s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 128, 64], model__learning_rate=0.1; total time=  59.2s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[128, 128, 64], model__learning_rate=0.1; total time=  59.0s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[256, 128, 64], model__learning_rate=0.01; total time= 1.2min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[256, 128, 64], model__learning_rate=0.001; total time= 1.3min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[256, 128, 64], model__learning_rate=0.001; total time= 1.3min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[256, 128, 64], model__learning_rate=0.01; total time= 1.3min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[256, 128, 64], model__learning_rate=0.1; total time= 1.2min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.2, model__layer_sizes=[256, 128, 64], model__learning_rate=0.1; total time= 1.3min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 64, 32], model__learning_rate=0.001; total time=  54.1s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 64, 32], model__learning_rate=0.001; total time=  53.3s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 64, 32], model__learning_rate=0.01; total time=  53.5s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 64, 32], model__learning_rate=0.01; total time=  52.2s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 64, 32], model__learning_rate=0.1; total time=  50.8s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 64, 32], model__learning_rate=0.1; total time=  51.6s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 32], model__learning_rate=0.001; total time=  46.8s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 32], model__learning_rate=0.001; total time=  46.3s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 32], model__learning_rate=0.01; total time=  46.6s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 32], model__learning_rate=0.01; total time=  47.4s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 32], model__learning_rate=0.1; total time=  46.4s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 32], model__learning_rate=0.1; total time=  47.1s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 64], model__learning_rate=0.001; total time=  51.1s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 64], model__learning_rate=0.001; total time=  51.6s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 64], model__learning_rate=0.01; total time=  51.7s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 64], model__learning_rate=0.01; total time=  51.4s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 64], model__learning_rate=0.1; total time=  52.4s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[64, 64], model__learning_rate=0.1; total time=  51.0s\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 128, 64], model__learning_rate=0.001; total time= 1.1min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 128, 64], model__learning_rate=0.001; total time= 1.1min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 128, 64], model__learning_rate=0.01; total time= 1.1min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 128, 64], model__learning_rate=0.01; total time= 1.2min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 128, 64], model__learning_rate=0.1; total time= 1.2min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[128, 128, 64], model__learning_rate=0.1; total time= 1.2min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[256, 128, 64], model__learning_rate=0.001; total time= 1.3min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[256, 128, 64], model__learning_rate=0.001; total time= 1.3min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[256, 128, 64], model__learning_rate=0.01; total time= 1.3min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[256, 128, 64], model__learning_rate=0.01; total time= 1.2min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[256, 128, 64], model__learning_rate=0.1; total time= 1.2min\n",
      "[CV] END batch_size=64, epochs=200, model__dropout_rate=0.5, model__layer_sizes=[256, 128, 64], model__learning_rate=0.1; total time= 1.1min\n",
      "Best Parameters:  {'batch_size': 64, 'epochs': 200, 'model__dropout_rate': 0.0, 'model__layer_sizes': [256, 128, 64], 'model__learning_rate': 0.001}\n",
      "Best Cross-Validation Score (MAE):  47.00816678902673\n",
      "Best Estimator:  KerasRegressor(\n",
      "\tmodel=<function construct_network_model at 0x30ac2c900>\n",
      "\tbuild_fn=None\n",
      "\twarm_start=False\n",
      "\trandom_state=None\n",
      "\toptimizer=rmsprop\n",
      "\tloss=None\n",
      "\tmetrics=None\n",
      "\tbatch_size=64\n",
      "\tvalidation_batch_size=None\n",
      "\tverbose=0\n",
      "\tcallbacks=None\n",
      "\tvalidation_split=0.0\n",
      "\tshuffle=True\n",
      "\trun_eagerly=False\n",
      "\tepochs=200\n",
      "\tmodel__input_dim=12\n",
      "\tmodel__dropout_rate=0.0\n",
      "\tmodel__layer_sizes=[256, 128, 64]\n",
      "\tmodel__learning_rate=0.001\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# Assuming you have defined KerasRegressor, construct_network_model,\n",
    "# X_train_scaled, and y_train elsewhere in your code.\n",
    "\n",
    "# --- Your Original Code ---\n",
    "\n",
    "# Define the model using KerasRegressor wrapper\n",
    "model = KerasRegressor(model=construct_network_model, verbose=0, model__input_dim=X_train_scaled.shape[1])\n",
    "\n",
    "# Define the early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_mae', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Define the parameter grid for the search\n",
    "param_grid = {\n",
    "    \"model__layer_sizes\": [\n",
    "        [128, 64, 32],\n",
    "        [64, 32],\n",
    "        [64, 64],\n",
    "        [128, 128, 64],\n",
    "        [256, 128, 64]\n",
    "    ],\n",
    "    \"model__dropout_rate\": [0.0, 0.2, 0.5],\n",
    "    \"batch_size\": [32, 64],\n",
    "    \"model__learning_rate\": [0.001, 0.01, 0.1],\n",
    "    \"epochs\": [200]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV\n",
    "grid = GridSearchCV(model, param_grid, cv=2, n_jobs=-2, scoring='neg_mean_absolute_error', verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "# The `callbacks` and `validation_split` are passed to the Keras model's fit method internally\n",
    "grid.fit(X_train_scaled, y_train, callbacks=[early_stop], validation_split=0.2)\n",
    "\n",
    "# Save the best model's weights\n",
    "grid.best_estimator_.model_.save(\"weights.best_v3.keras\")\n",
    "\n",
    "\n",
    "# --- Retrieving and Printing the Results ---\n",
    "\n",
    "# 1. Print the best parameter combination found\n",
    "print(\"Best Parameters: \", grid.best_params_)\n",
    "\n",
    "# 2. Print the best cross-validation score\n",
    "# The score is 'neg_mean_absolute_error', so we multiply by -1 to get the actual MAE.\n",
    "print(\"Best Cross-Validation Score (MAE): \", -grid.best_score_)\n",
    "\n",
    "# 3. Get the best estimator (the model with the best parameters)\n",
    "# This model has been re-trained on the entire dataset provided to .fit()\n",
    "best_model = grid.best_estimator_\n",
    "print(\"Best Estimator: \", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "23d13fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guanzhou/miniforge3/envs/ai-env/lib/python3.11/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m3,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,545</span> (174.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,545\u001b[0m (174.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,545</span> (174.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,545\u001b[0m (174.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a Sequential model, which is a linear stack of layers.\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first Dense layer with 256 units, based on 'model__layer_sizes': [256, 128, 64].\n",
    "# The input_dim remains 11, corresponding to the number of features in your data.\n",
    "model.add(Dense(256, activation='relu', input_dim=12))\n",
    "\n",
    "# Add the second Dense layer with 128 units.\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add the third Dense layer with 64 units.\n",
    "# Note: Since 'model__dropout_rate' is 0.0, no Dropout layer is added.\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add a final Dense layer with 1 unit for the regression output.\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Create an Adam optimizer instance with the specified learning rate from 'model__learning_rate'.\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model with the custom optimizer and Mean Absolute Error (MAE) loss function.\n",
    "model.compile(optimizer=optimizer, loss='mae', metrics=['mae'])\n",
    "\n",
    "# Display a summary of the new model architecture.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939cba4",
   "metadata": {},
   "source": [
    "Trainning and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "23404c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - loss: 114.5117 - mae: 114.5117 - val_loss: 99.6767 - val_mae: 99.6767\n",
      "Epoch 2/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - loss: 94.5915 - mae: 94.5915 - val_loss: 86.2196 - val_mae: 86.2196\n",
      "Epoch 3/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 82.8893 - mae: 82.8893 - val_loss: 79.1565 - val_mae: 79.1565\n",
      "Epoch 4/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 76.3923 - mae: 76.3923 - val_loss: 72.9468 - val_mae: 72.9468\n",
      "Epoch 5/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - loss: 71.5365 - mae: 71.5365 - val_loss: 68.4590 - val_mae: 68.4590\n",
      "Epoch 6/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 67.5155 - mae: 67.5155 - val_loss: 66.3746 - val_mae: 66.3746\n",
      "Epoch 7/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 65.0814 - mae: 65.0814 - val_loss: 67.5686 - val_mae: 67.5686\n",
      "Epoch 8/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 62.5789 - mae: 62.5789 - val_loss: 63.1530 - val_mae: 63.1530\n",
      "Epoch 9/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 60.2294 - mae: 60.2294 - val_loss: 60.7371 - val_mae: 60.7371\n",
      "Epoch 10/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 58.1556 - mae: 58.1556 - val_loss: 57.3811 - val_mae: 57.3811\n",
      "Epoch 11/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 56.2422 - mae: 56.2422 - val_loss: 55.9252 - val_mae: 55.9252\n",
      "Epoch 12/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 54.7527 - mae: 54.7527 - val_loss: 53.3980 - val_mae: 53.3980\n",
      "Epoch 13/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 52.9901 - mae: 52.9901 - val_loss: 55.2124 - val_mae: 55.2124\n",
      "Epoch 14/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 52.1616 - mae: 52.1616 - val_loss: 51.1390 - val_mae: 51.1390\n",
      "Epoch 15/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 51.3291 - mae: 51.3291 - val_loss: 51.6219 - val_mae: 51.6219\n",
      "Epoch 16/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 50.4711 - mae: 50.4711 - val_loss: 49.7808 - val_mae: 49.7808\n",
      "Epoch 17/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 49.9669 - mae: 49.9669 - val_loss: 50.3221 - val_mae: 50.3221\n",
      "Epoch 18/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 49.6649 - mae: 49.6649 - val_loss: 49.7830 - val_mae: 49.7830\n",
      "Epoch 19/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 49.0186 - mae: 49.0186 - val_loss: 50.2673 - val_mae: 50.2673\n",
      "Epoch 20/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 48.2376 - mae: 48.2376 - val_loss: 49.0192 - val_mae: 49.0192\n",
      "Epoch 21/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 47.8507 - mae: 47.8507 - val_loss: 48.5410 - val_mae: 48.5410\n",
      "Epoch 22/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 47.1529 - mae: 47.1529 - val_loss: 48.5654 - val_mae: 48.5654\n",
      "Epoch 23/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - loss: 47.0809 - mae: 47.0809 - val_loss: 50.2607 - val_mae: 50.2607\n",
      "Epoch 24/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 46.7643 - mae: 46.7643 - val_loss: 47.2498 - val_mae: 47.2498\n",
      "Epoch 25/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 46.4165 - mae: 46.4165 - val_loss: 47.8611 - val_mae: 47.8611\n",
      "Epoch 26/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 46.7266 - mae: 46.7266 - val_loss: 47.3306 - val_mae: 47.3306\n",
      "Epoch 27/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 45.9299 - mae: 45.9299 - val_loss: 46.3191 - val_mae: 46.3191\n",
      "Epoch 28/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 45.2819 - mae: 45.2819 - val_loss: 47.3584 - val_mae: 47.3584\n",
      "Epoch 29/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 45.4358 - mae: 45.4358 - val_loss: 47.3591 - val_mae: 47.3591\n",
      "Epoch 30/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 45.4315 - mae: 45.4315 - val_loss: 47.9054 - val_mae: 47.9054\n",
      "Epoch 31/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 45.1263 - mae: 45.1263 - val_loss: 50.8208 - val_mae: 50.8208\n",
      "Epoch 32/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 44.7512 - mae: 44.7512 - val_loss: 45.8267 - val_mae: 45.8267\n",
      "Epoch 33/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 44.4844 - mae: 44.4844 - val_loss: 46.1073 - val_mae: 46.1073\n",
      "Epoch 34/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 44.4712 - mae: 44.4712 - val_loss: 46.2271 - val_mae: 46.2271\n",
      "Epoch 35/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 44.2979 - mae: 44.2979 - val_loss: 46.7686 - val_mae: 46.7686\n",
      "Epoch 36/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 43.9178 - mae: 43.9178 - val_loss: 46.4563 - val_mae: 46.4563\n",
      "Epoch 37/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 43.5937 - mae: 43.5937 - val_loss: 45.7790 - val_mae: 45.7790\n",
      "Epoch 38/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 43.8031 - mae: 43.8031 - val_loss: 46.1335 - val_mae: 46.1335\n",
      "Epoch 39/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 43.2343 - mae: 43.2343 - val_loss: 48.6267 - val_mae: 48.6267\n",
      "Epoch 40/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 42.8593 - mae: 42.8593 - val_loss: 45.7213 - val_mae: 45.7213\n",
      "Epoch 41/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 43.3111 - mae: 43.3111 - val_loss: 46.1147 - val_mae: 46.1147\n",
      "Epoch 42/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 42.8796 - mae: 42.8796 - val_loss: 45.7296 - val_mae: 45.7296\n",
      "Epoch 43/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 42.5039 - mae: 42.5039 - val_loss: 44.6073 - val_mae: 44.6073\n",
      "Epoch 44/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 42.7993 - mae: 42.7993 - val_loss: 47.8626 - val_mae: 47.8626\n",
      "Epoch 45/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 42.1601 - mae: 42.1601 - val_loss: 46.8552 - val_mae: 46.8552\n",
      "Epoch 46/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 42.0698 - mae: 42.0698 - val_loss: 45.7955 - val_mae: 45.7955\n",
      "Epoch 47/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 42.3584 - mae: 42.3584 - val_loss: 45.7077 - val_mae: 45.7077\n",
      "Epoch 48/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 41.8398 - mae: 41.8398 - val_loss: 49.1926 - val_mae: 49.1926\n",
      "Epoch 49/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 41.7215 - mae: 41.7215 - val_loss: 44.2253 - val_mae: 44.2253\n",
      "Epoch 50/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 41.4063 - mae: 41.4063 - val_loss: 45.8246 - val_mae: 45.8246\n",
      "Epoch 51/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 41.5435 - mae: 41.5435 - val_loss: 44.8139 - val_mae: 44.8139\n",
      "Epoch 52/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 41.3973 - mae: 41.3973 - val_loss: 44.6991 - val_mae: 44.6991\n",
      "Epoch 53/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 41.4344 - mae: 41.4344 - val_loss: 46.3070 - val_mae: 46.3070\n",
      "Epoch 54/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 41.0769 - mae: 41.0769 - val_loss: 45.0787 - val_mae: 45.0787\n",
      "Epoch 55/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 41.0107 - mae: 41.0107 - val_loss: 46.3311 - val_mae: 46.3311\n",
      "Epoch 56/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 40.7771 - mae: 40.7771 - val_loss: 45.2406 - val_mae: 45.2406\n",
      "Epoch 57/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 40.5463 - mae: 40.5463 - val_loss: 45.9529 - val_mae: 45.9529\n",
      "Epoch 58/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 40.7145 - mae: 40.7145 - val_loss: 46.2074 - val_mae: 46.2074\n",
      "Epoch 59/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 40.4318 - mae: 40.4318 - val_loss: 44.6261 - val_mae: 44.6261\n",
      "Epoch 60/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 40.1199 - mae: 40.1199 - val_loss: 45.0332 - val_mae: 45.0332\n",
      "Epoch 61/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 39.8829 - mae: 39.8829 - val_loss: 44.6011 - val_mae: 44.6011\n",
      "Epoch 62/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 39.8575 - mae: 39.8575 - val_loss: 44.8951 - val_mae: 44.8951\n",
      "Epoch 63/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 39.8439 - mae: 39.8439 - val_loss: 46.2374 - val_mae: 46.2374\n",
      "Epoch 64/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 39.5950 - mae: 39.5950 - val_loss: 45.6642 - val_mae: 45.6642\n",
      "Epoch 65/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 39.0478 - mae: 39.0478 - val_loss: 44.8905 - val_mae: 44.8905\n",
      "Epoch 66/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 39.0216 - mae: 39.0216 - val_loss: 44.0042 - val_mae: 44.0042\n",
      "Epoch 67/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 39.6199 - mae: 39.6199 - val_loss: 45.0706 - val_mae: 45.0706\n",
      "Epoch 68/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 39.3240 - mae: 39.3240 - val_loss: 45.0744 - val_mae: 45.0744\n",
      "Epoch 69/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 38.7253 - mae: 38.7253 - val_loss: 45.6580 - val_mae: 45.6580\n",
      "Epoch 70/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 38.9221 - mae: 38.9221 - val_loss: 47.1678 - val_mae: 47.1678\n",
      "Epoch 71/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 38.8590 - mae: 38.8590 - val_loss: 44.0261 - val_mae: 44.0261\n",
      "Epoch 72/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 38.4227 - mae: 38.4227 - val_loss: 43.6009 - val_mae: 43.6009\n",
      "Epoch 73/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 38.3510 - mae: 38.3510 - val_loss: 44.3223 - val_mae: 44.3223\n",
      "Epoch 74/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 38.4967 - mae: 38.4967 - val_loss: 44.3600 - val_mae: 44.3600\n",
      "Epoch 75/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 38.4779 - mae: 38.4779 - val_loss: 43.9120 - val_mae: 43.9120\n",
      "Epoch 76/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 37.8641 - mae: 37.8641 - val_loss: 45.1811 - val_mae: 45.1811\n",
      "Epoch 77/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 37.8209 - mae: 37.8209 - val_loss: 46.2749 - val_mae: 46.2749\n",
      "Epoch 78/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 38.2269 - mae: 38.2269 - val_loss: 43.9912 - val_mae: 43.9912\n",
      "Epoch 79/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 37.8060 - mae: 37.8060 - val_loss: 44.3497 - val_mae: 44.3497\n",
      "Epoch 80/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 37.8322 - mae: 37.8322 - val_loss: 46.3133 - val_mae: 46.3133\n",
      "Epoch 81/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 37.7909 - mae: 37.7909 - val_loss: 44.7081 - val_mae: 44.7081\n",
      "Epoch 82/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 37.4106 - mae: 37.4106 - val_loss: 44.0777 - val_mae: 44.0777\n",
      "Epoch 83/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 37.1226 - mae: 37.1226 - val_loss: 45.2025 - val_mae: 45.2025\n",
      "Epoch 84/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 37.0559 - mae: 37.0559 - val_loss: 43.9523 - val_mae: 43.9523\n",
      "Epoch 85/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 37.0257 - mae: 37.0257 - val_loss: 44.0622 - val_mae: 44.0622\n",
      "Epoch 86/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 37.3066 - mae: 37.3066 - val_loss: 44.2332 - val_mae: 44.2332\n",
      "Epoch 87/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 36.8813 - mae: 36.8813 - val_loss: 44.2475 - val_mae: 44.2475\n",
      "Epoch 88/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 36.8047 - mae: 36.8047 - val_loss: 44.0742 - val_mae: 44.0742\n",
      "Epoch 89/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 36.2317 - mae: 36.2317 - val_loss: 43.8619 - val_mae: 43.8619\n",
      "Epoch 90/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 36.5466 - mae: 36.5466 - val_loss: 43.4610 - val_mae: 43.4610\n",
      "Epoch 91/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 36.6879 - mae: 36.6879 - val_loss: 45.1525 - val_mae: 45.1525\n",
      "Epoch 92/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 35.9940 - mae: 35.9940 - val_loss: 45.1177 - val_mae: 45.1177\n",
      "Epoch 93/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 36.2709 - mae: 36.2709 - val_loss: 44.0597 - val_mae: 44.0597\n",
      "Epoch 94/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 36.2868 - mae: 36.2868 - val_loss: 43.7889 - val_mae: 43.7889\n",
      "Epoch 95/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 36.2979 - mae: 36.2979 - val_loss: 43.8622 - val_mae: 43.8622\n",
      "Epoch 96/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 36.1047 - mae: 36.1047 - val_loss: 43.7611 - val_mae: 43.7611\n",
      "Epoch 97/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 35.5084 - mae: 35.5084 - val_loss: 44.0522 - val_mae: 44.0522\n",
      "Epoch 98/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 35.5555 - mae: 35.5555 - val_loss: 43.8356 - val_mae: 43.8356\n",
      "Epoch 99/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562us/step - loss: 35.6390 - mae: 35.6390 - val_loss: 44.1978 - val_mae: 44.1978\n",
      "Epoch 100/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - loss: 35.4881 - mae: 35.4881 - val_loss: 43.6927 - val_mae: 43.6927\n",
      "Epoch 101/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 34.9746 - mae: 34.9746 - val_loss: 43.3598 - val_mae: 43.3598\n",
      "Epoch 102/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - loss: 35.0437 - mae: 35.0437 - val_loss: 44.5419 - val_mae: 44.5419\n",
      "Epoch 103/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 34.9804 - mae: 34.9804 - val_loss: 44.4301 - val_mae: 44.4301\n",
      "Epoch 104/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 34.9455 - mae: 34.9455 - val_loss: 43.2637 - val_mae: 43.2637\n",
      "Epoch 105/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 35.0286 - mae: 35.0286 - val_loss: 44.3581 - val_mae: 44.3581\n",
      "Epoch 106/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 34.7659 - mae: 34.7659 - val_loss: 45.3075 - val_mae: 45.3075\n",
      "Epoch 107/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 34.5546 - mae: 34.5546 - val_loss: 44.4099 - val_mae: 44.4099\n",
      "Epoch 108/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 34.5188 - mae: 34.5188 - val_loss: 44.2637 - val_mae: 44.2637\n",
      "Epoch 109/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 34.1189 - mae: 34.1189 - val_loss: 43.7078 - val_mae: 43.7078\n",
      "Epoch 110/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 33.9886 - mae: 33.9886 - val_loss: 44.7614 - val_mae: 44.7614\n",
      "Epoch 111/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 34.3791 - mae: 34.3791 - val_loss: 44.6938 - val_mae: 44.6938\n",
      "Epoch 112/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 34.0588 - mae: 34.0588 - val_loss: 44.2304 - val_mae: 44.2304\n",
      "Epoch 113/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 34.3527 - mae: 34.3527 - val_loss: 43.2135 - val_mae: 43.2135\n",
      "Epoch 114/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 34.1326 - mae: 34.1326 - val_loss: 43.4367 - val_mae: 43.4367\n",
      "Epoch 115/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 33.7849 - mae: 33.7849 - val_loss: 42.9002 - val_mae: 42.9002\n",
      "Epoch 116/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 33.7277 - mae: 33.7277 - val_loss: 43.9601 - val_mae: 43.9601\n",
      "Epoch 117/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 33.8677 - mae: 33.8677 - val_loss: 43.2215 - val_mae: 43.2215\n",
      "Epoch 118/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 33.1456 - mae: 33.1456 - val_loss: 43.8561 - val_mae: 43.8561\n",
      "Epoch 119/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 33.5911 - mae: 33.5911 - val_loss: 43.3154 - val_mae: 43.3154\n",
      "Epoch 120/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 33.2966 - mae: 33.2966 - val_loss: 43.2189 - val_mae: 43.2189\n",
      "Epoch 121/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 33.2949 - mae: 33.2949 - val_loss: 45.2426 - val_mae: 45.2426\n",
      "Epoch 122/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 32.7910 - mae: 32.7910 - val_loss: 44.4090 - val_mae: 44.4090\n",
      "Epoch 123/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 32.9619 - mae: 32.9619 - val_loss: 43.0903 - val_mae: 43.0903\n",
      "Epoch 124/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 32.8338 - mae: 32.8338 - val_loss: 44.5677 - val_mae: 44.5677\n",
      "Epoch 125/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 33.1121 - mae: 33.1121 - val_loss: 44.8111 - val_mae: 44.8111\n",
      "Epoch 126/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 32.9953 - mae: 32.9953 - val_loss: 43.4542 - val_mae: 43.4542\n",
      "Epoch 127/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 32.4276 - mae: 32.4276 - val_loss: 43.0935 - val_mae: 43.0935\n",
      "Epoch 128/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 32.4636 - mae: 32.4636 - val_loss: 45.4796 - val_mae: 45.4796\n",
      "Epoch 129/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 32.5287 - mae: 32.5287 - val_loss: 44.0254 - val_mae: 44.0254\n",
      "Epoch 130/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 32.3320 - mae: 32.3320 - val_loss: 43.2319 - val_mae: 43.2319\n",
      "Epoch 131/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 32.7333 - mae: 32.7333 - val_loss: 44.5106 - val_mae: 44.5106\n",
      "Epoch 132/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 32.3313 - mae: 32.3313 - val_loss: 43.0851 - val_mae: 43.0851\n",
      "Epoch 133/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 32.0021 - mae: 32.0021 - val_loss: 43.8187 - val_mae: 43.8187\n",
      "Epoch 134/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 32.1693 - mae: 32.1693 - val_loss: 43.3610 - val_mae: 43.3610\n",
      "Epoch 135/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 31.6900 - mae: 31.6900 - val_loss: 43.1372 - val_mae: 43.1372\n",
      "Epoch 136/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 32.1655 - mae: 32.1655 - val_loss: 44.1337 - val_mae: 44.1337\n",
      "Epoch 137/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 31.7836 - mae: 31.7836 - val_loss: 43.8459 - val_mae: 43.8459\n",
      "Epoch 138/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 31.5486 - mae: 31.5486 - val_loss: 44.1282 - val_mae: 44.1282\n",
      "Epoch 139/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 31.5953 - mae: 31.5953 - val_loss: 43.2315 - val_mae: 43.2315\n",
      "Epoch 140/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 31.5230 - mae: 31.5230 - val_loss: 44.0747 - val_mae: 44.0747\n",
      "Epoch 141/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 31.5027 - mae: 31.5027 - val_loss: 44.2552 - val_mae: 44.2552\n",
      "Epoch 142/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - loss: 31.3481 - mae: 31.3481 - val_loss: 43.1773 - val_mae: 43.1773\n",
      "Epoch 143/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 31.4084 - mae: 31.4084 - val_loss: 43.9342 - val_mae: 43.9342\n",
      "Epoch 144/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 31.5634 - mae: 31.5634 - val_loss: 43.1966 - val_mae: 43.1966\n",
      "Epoch 145/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 31.4471 - mae: 31.4471 - val_loss: 43.9390 - val_mae: 43.9390\n",
      "Epoch 146/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 31.3210 - mae: 31.3210 - val_loss: 43.4678 - val_mae: 43.4678\n",
      "Epoch 147/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 31.1759 - mae: 31.1759 - val_loss: 43.2415 - val_mae: 43.2415\n",
      "Epoch 148/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 30.8751 - mae: 30.8751 - val_loss: 44.0605 - val_mae: 44.0605\n",
      "Epoch 149/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 30.7918 - mae: 30.7918 - val_loss: 43.2113 - val_mae: 43.2113\n",
      "Epoch 150/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 31.1256 - mae: 31.1256 - val_loss: 43.3580 - val_mae: 43.3580\n",
      "Epoch 151/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 30.4986 - mae: 30.4986 - val_loss: 43.2578 - val_mae: 43.2578\n",
      "Epoch 152/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 30.6081 - mae: 30.6081 - val_loss: 44.3407 - val_mae: 44.3407\n",
      "Epoch 153/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 30.6176 - mae: 30.6176 - val_loss: 44.5096 - val_mae: 44.5096\n",
      "Epoch 154/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 30.9512 - mae: 30.9512 - val_loss: 43.8588 - val_mae: 43.8588\n",
      "Epoch 155/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 30.2104 - mae: 30.2104 - val_loss: 43.5936 - val_mae: 43.5936\n",
      "Epoch 156/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - loss: 30.4677 - mae: 30.4677 - val_loss: 43.9138 - val_mae: 43.9138\n",
      "Epoch 157/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 29.9777 - mae: 29.9777 - val_loss: 42.7730 - val_mae: 42.7730\n",
      "Epoch 158/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 30.2085 - mae: 30.2085 - val_loss: 42.9375 - val_mae: 42.9375\n",
      "Epoch 159/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 29.8056 - mae: 29.8056 - val_loss: 44.2198 - val_mae: 44.2198\n",
      "Epoch 160/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 29.7622 - mae: 29.7622 - val_loss: 43.0378 - val_mae: 43.0378\n",
      "Epoch 161/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 30.1400 - mae: 30.1400 - val_loss: 43.7094 - val_mae: 43.7094\n",
      "Epoch 162/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 29.7593 - mae: 29.7593 - val_loss: 42.6108 - val_mae: 42.6108\n",
      "Epoch 163/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 30.0010 - mae: 30.0010 - val_loss: 43.6455 - val_mae: 43.6455\n",
      "Epoch 164/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 29.9771 - mae: 29.9771 - val_loss: 44.2640 - val_mae: 44.2640\n",
      "Epoch 165/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 29.6988 - mae: 29.6988 - val_loss: 43.3250 - val_mae: 43.3250\n",
      "Epoch 166/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 29.5767 - mae: 29.5767 - val_loss: 42.4898 - val_mae: 42.4898\n",
      "Epoch 167/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 29.4256 - mae: 29.4256 - val_loss: 42.5990 - val_mae: 42.5990\n",
      "Epoch 168/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 29.6119 - mae: 29.6119 - val_loss: 43.1057 - val_mae: 43.1057\n",
      "Epoch 169/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 29.2853 - mae: 29.2853 - val_loss: 43.5789 - val_mae: 43.5789\n",
      "Epoch 170/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 29.4963 - mae: 29.4963 - val_loss: 42.3183 - val_mae: 42.3183\n",
      "Epoch 171/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 29.1482 - mae: 29.1482 - val_loss: 43.1032 - val_mae: 43.1032\n",
      "Epoch 172/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 28.7844 - mae: 28.7844 - val_loss: 43.8321 - val_mae: 43.8321\n",
      "Epoch 173/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - loss: 29.2482 - mae: 29.2482 - val_loss: 44.1710 - val_mae: 44.1710\n",
      "Epoch 174/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - loss: 29.3033 - mae: 29.3033 - val_loss: 42.9680 - val_mae: 42.9680\n",
      "Epoch 175/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 29.0203 - mae: 29.0203 - val_loss: 43.4956 - val_mae: 43.4956\n",
      "Epoch 176/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - loss: 28.8969 - mae: 28.8969 - val_loss: 43.3795 - val_mae: 43.3795\n",
      "Epoch 177/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 29.0979 - mae: 29.0979 - val_loss: 42.4828 - val_mae: 42.4828\n",
      "Epoch 178/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 28.8600 - mae: 28.8600 - val_loss: 43.2547 - val_mae: 43.2547\n",
      "Epoch 179/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 29.1592 - mae: 29.1592 - val_loss: 44.2964 - val_mae: 44.2964\n",
      "Epoch 180/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 28.9024 - mae: 28.9024 - val_loss: 43.1083 - val_mae: 43.1083\n",
      "Epoch 181/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 28.6849 - mae: 28.6849 - val_loss: 43.2867 - val_mae: 43.2867\n",
      "Epoch 182/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 28.6788 - mae: 28.6788 - val_loss: 43.0767 - val_mae: 43.0767\n",
      "Epoch 183/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 28.3024 - mae: 28.3024 - val_loss: 43.0695 - val_mae: 43.0695\n",
      "Epoch 184/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 28.3697 - mae: 28.3697 - val_loss: 43.5261 - val_mae: 43.5261\n",
      "Epoch 185/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 28.6833 - mae: 28.6833 - val_loss: 44.4062 - val_mae: 44.4062\n",
      "Epoch 186/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 28.4867 - mae: 28.4867 - val_loss: 45.1391 - val_mae: 45.1391\n",
      "Epoch 187/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 28.5488 - mae: 28.5488 - val_loss: 44.1490 - val_mae: 44.1490\n",
      "Epoch 188/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 28.2431 - mae: 28.2431 - val_loss: 43.9906 - val_mae: 43.9906\n",
      "Epoch 189/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 28.0292 - mae: 28.0292 - val_loss: 43.3823 - val_mae: 43.3823\n",
      "Epoch 190/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 28.0271 - mae: 28.0271 - val_loss: 42.9449 - val_mae: 42.9449\n",
      "Epoch 191/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 27.9135 - mae: 27.9135 - val_loss: 44.0912 - val_mae: 44.0912\n",
      "Epoch 192/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 27.7098 - mae: 27.7098 - val_loss: 45.1959 - val_mae: 45.1959\n",
      "Epoch 193/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 27.8730 - mae: 27.8730 - val_loss: 43.2132 - val_mae: 43.2132\n",
      "Epoch 194/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 27.5182 - mae: 27.5182 - val_loss: 43.2962 - val_mae: 43.2962\n",
      "Epoch 195/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 27.5199 - mae: 27.5199 - val_loss: 43.6559 - val_mae: 43.6559\n",
      "Epoch 196/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 27.4019 - mae: 27.4019 - val_loss: 43.6022 - val_mae: 43.6022\n",
      "Epoch 197/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 27.7962 - mae: 27.7962 - val_loss: 44.1389 - val_mae: 44.1389\n",
      "Epoch 198/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 27.8134 - mae: 27.8134 - val_loss: 42.8190 - val_mae: 42.8190\n",
      "Epoch 199/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 27.3448 - mae: 27.3448 - val_loss: 43.4867 - val_mae: 43.4867\n",
      "Epoch 200/200\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 27.5378 - mae: 27.5378 - val_loss: 43.8559 - val_mae: 43.8559\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model to the training data, specifying validation split, epochs, and batch size.\n",
    "hist = model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=200, batch_size=32)\n",
    "# Set the style of the plots using Seaborn.\n",
    "sns.set()\n",
    "# Extract the training and validation Mean Absolute Error (MAE) from the training history.\n",
    "err = hist.history['mae']\n",
    "val_err = hist.history['val_mae']\n",
    "# Define the number of epochs.\n",
    "epochs = range(1, len(err) + 1)\n",
    "# Plot the Training MAE and Validation MAE over epochs.\n",
    "plt.plot(epochs, err, '-', label='Training MAE')\n",
    "plt.plot(epochs, val_err, ':', label='Validation MAE')\n",
    "plt.title('Training and Validation MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.legend(loc='upper right')\n",
    "plt.plot()\n",
    "# Use the trained model to predict on the test data.\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8edf0",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1baa1093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error of NN: 42.739464515577936\n",
      "Mean Squared Error: 4707.799792268139\n",
      "R-squared of NN: 0.851326744432718\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Mean Absolute Error (MAE) between the true and predicted values.\n",
    "mae_nn = mean_absolute_error(y_test, y_pred)\n",
    "# Calculate the Root Mean Squared Error (RMSE) between the true and predicted values.\n",
    "mse_nn = mean_squared_error(y_test, y_pred)\n",
    "# Calculate the R-squared (R2) score, a measure of how well the model explains the variance in the data.\n",
    "r2_nn = r2_score(y_test, y_pred)\n",
    "# Print the calculated metrics.\n",
    "print(f\"Mean Absolute Error of NN: {mae_nn}\")\n",
    "print(f\"Mean Squared Error: {mse_nn}\")\n",
    "print(f\"R-squared of NN: {r2_nn}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0afcdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LR_MAE': 104.79577059911452, 'LR_R2': 0.3879974354720257, 'LR_MSE': 19379.312944744703}\n"
     ]
    }
   ],
   "source": [
    "# A super-fast baseline, just for context\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "\n",
    "print({\"LR_MAE\": mae_lr, \"LR_R2\": r2_lr, \"LR_MSE\":mse_lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38b145c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>104.795771</td>\n",
       "      <td>0.387997</td>\n",
       "      <td>19379.312945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>25.364293</td>\n",
       "      <td>0.943788</td>\n",
       "      <td>1779.967895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model         MAE        R2           MSE\n",
       "0  Linear Regression  104.795771  0.387997  19379.312945\n",
       "1         Neural Net   25.364293  0.943788   1779.967895"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "results = pd.DataFrame([\n",
    "    {'Model': 'Linear Regression', 'MAE': mae_lr, 'R2': r2_lr, \"MSE\":mse_lr},\n",
    "    {'Model': 'Neural Net', 'MAE': mae_nn, 'R2': r2_nn, \"MSE\":mse_nn},\n",
    "])\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
